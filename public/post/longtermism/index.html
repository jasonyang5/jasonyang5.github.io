<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>In Defense of Effective Altruism after SBF | Jason's Blog</title><meta name=keywords content><meta name=description content="SBF&rsquo;s fraud does not implicate my conception of Effective Altruism because I do not think he was actually an effective altruist."><meta name=author content="Me"><link rel=canonical href=https://jasonyang5.github.io/public/post/longtermism/><meta name=google-site-verification content="XYZabc"><link href=/public/assets/css/stylesheet.min.1eef9c740af75b4e5f773d9d5f757e03e3df71f3a308e73070cc73d55a59a7d7.css integrity="sha256-Hu+cdAr3W05fdz2dX3V+A+PfcfOjCOcwcMxz1VpZp9c=" rel="preload stylesheet" as=style><link rel=icon href=https://jasonyang5.github.io/public/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://jasonyang5.github.io/public/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://jasonyang5.github.io/public/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://jasonyang5.github.io/public/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://jasonyang5.github.io/public/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-123-45','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="In Defense of Effective Altruism after SBF"><meta property="og:description" content="SBF&rsquo;s fraud does not implicate my conception of Effective Altruism because I do not think he was actually an effective altruist."><meta property="og:type" content="article"><meta property="og:url" content="https://jasonyang5.github.io/public/post/longtermism/"><meta property="og:image" content="https://jasonyang5.github.io/public/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:published_time" content="2022-12-03T09:48:39-05:00"><meta property="article:modified_time" content="2022-12-03T09:48:39-05:00"><meta property="og:site_name" content="Jason's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jasonyang5.github.io/public/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="In Defense of Effective Altruism after SBF"><meta name=twitter:description content="SBF&rsquo;s fraud does not implicate my conception of Effective Altruism because I do not think he was actually an effective altruist."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://jasonyang5.github.io/public/post/"},{"@type":"ListItem","position":2,"name":"In Defense of Effective Altruism after SBF","item":"https://jasonyang5.github.io/public/post/longtermism/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"In Defense of Effective Altruism after SBF","name":"In Defense of Effective Altruism after SBF","description":"SBF\u0026amp;rsquo;s fraud does not implicate my conception of Effective Altruism because I do not think he was actually an effective altruist.","keywords":[],"articleBody":"Next threads to do\n Talk about social signalling Once over the whole thing Push out  Intro to new Blog Category I’m adding a new category called “Takes”. For context, I enjoy taking time to think about my decisions, my process for making decisions, and how that relates to new info out in the world. Sometimes, this produces a hot take. These posts force me to organize that thinking and hopefully will provide entertainment for others. I try make reasonable claims most of the time, but mostly this is an exercise in logical thinking based on my experiences rather than researching to find out what’s true.\nSummary I don’t believe true effective altruists can hold billions of dollars for themselves (even if it’s not cash and in some less liquid asset ie stock needed to keep ownership).\nEffective altruism is fairly broad with many interpretations. I think effective altruists seek to sustainably maximize well being for those they believe have moral relevance. I add sustainable because most people (myself included) wouldn’t be interested in being effective altruists if doing so came at the expense of their whole life.\nIn this post, I consider two potential justifications for holding a billion dollars in assets. 1) that it’s part of a broader earning to give strategy and 2) that it’s needed to maintain decision rights of an impactful company.\nEarning to Give In this case, the altruists that are earning to give make a choice between the following (pretty long) list\n Cause A Cause B Cause C … Keeping the money for yourself  Let’s break this down into 2 sub choices: choosing between keeping the money and donating and with that donation pool choosing between the many causes to donate to.\nKeeping vs Donating\nI see the choice between donating and keeping driven by 2 main points\n Improving sustainability of future giving (buying food, basic hobbies, basic socialization, or capital investment) Preference (are you actually altruistic?)  Intuitively, effective altruists are more defined by their preference between donating and keeping money after adjusting for the fact that there is some reasonable amount they have to spend on themselves so they don’t go insane.\nThis feels obvious to me, but I’ll say that holding on to a billion dollars cannot possibly be justified by food, hobbies, and socialization. Even having multiple comically expensive hobbies like the same person buying a new ferrari every 2 months, 20 haute coture dresses at Paris fashion week, and a golf membership at Augusta National Golf Club each year only liberally sums to $3m per year (meaning you could set aside 15% of that $1b for yourself and donate the rest while sustaining “basic hobbies and socialization needs”). A billion dollars is a lot.\nCapital investment could warrant keeping money for yourself. Suppose you’re a entrepreneurial visionary and put out a good number of bangers every year and earn well over 20% per year on that capital. Then, why not just keep doing that and then donate a lump sum?\nFirst, that type of donation profile isn’t particularly sustainable and puts the job of efficient financing and investing through time on the nonprofits. This is problematic because the typical nonprofit has a bad investment opportunity set for transferring wealth into the future (no space in the top VC, hedge fund, private equity allocations) and an even worse one for taking wealth from the future (no capitalization, greater risk of default so likely have expensive financing).\nSecond, it’s fairly undemocratic. This mode of donation makes the EA agenda concentrated in the hands of a few “key moments” and “key players” when I think should be more of a ongoing negotiation. It seems fair to say that those with billions of dollars have different preferences (ethical or otherwise) than those without which skews the ‘moral’ agenda so to speak. For example, many (Elon Musk, SBF, Bezos, Bill Gates to an extent) are focused on longtermism and space exploration. It’s a fine and obviously valuable cause, but I’m skeptical that it’s the correct allocation. See the below point on Cause A vs Cause B to see why I think we should have a more evenly weighted allocation.\nThird, does this really happen in practice?\nCause A vs Cause B\nSub choice 2 is between causes. I think causes are impossible to reason between because any unified framework that compares causes will have extremely wide error bands that make the comparison inconclusive at best or entirely subjective at worst.\nTake a classic example - global development aid versus minimizing existential risk. Let’s use the expected quality adjusted life years framework for both. This requires 3 ingredients: the number of people benefitted, the quality of life improvement for those benefitted, and the probability that the intervention works.\nGlobal development aid\n Number of people benefitted - known. Just take the population of countries in question. Quality of life improvement - very difficult to compute, many conceptions of quality and several unexpected interaction terms (e.g. will development aid result in the government underinvest in its own infrastructure?) Probability - more or less known if you choose a vetted charity with real research/randomized controlled trials backing the interventions.  Existential risk\n Number of people benefitted - mostly known. Under reasonable assumptions, you could extrapolate the number of people that survive based on how long humanity survives. This number is very very high. Quality of life improvement - basically throwing darts. Quality of life might be better than today given what we know about the past, but it could seriously turn for the worse in the long run. Who’s to say some dictator doesn’t take over the world in 500 years and kill everybody’s quality of life for the next 500? It’s really hard to reason out all the possibilities when you are thinking about the world 1,000 years in the future. Probability - hard to argue a particular intervention actually moves the needle. This is a rant for another time, but just because the intervention could possibly/concievably work does not mean it has a positive probability of working. You can have possible outcomes that have 0 probability (e.g. picking a random real number from a hat of numbers uniformly distributed between 0 and 1). If the intervention possibly works but probability is still 0, the expected benefit of the intervention is still 0.  You could do this comparison for several causes and end up in a spot with false precision - you’re multiplying/adding together numbers with extremely wide error bands. It’s not really any less subjective than choosing on vibes.\nManaging on an Impactful Company Some companies have materially changed the world (e.g. Azure/AWS efficient cloud computing, Tesla forcing the industry into EV’s), and maintaining material management rights over the firm requires potentially billions of dollars in stock. The key here then is the marginal benefit of a manager/planner requiring stock to make those decisions rather than an individual contributor producing the innovations where holding stock isn’t actually needed.\nI have two main objections to keeping stock to drive the direction of the company.\nFirst, it’s important to remember the objective is to generally improve well being for the world rather than just the shareholders. So, it doesn’t really matter who is providing the important services but rather that someone just does it. So, it’s hard to justify the marginal dollars kept/spent on taking decision rights from someone else that is probably perfectly capable of running the company. On the innovation side, it’s not clear why managers are the key driver over individual contributors coming up with ideas (that don’t need stock to do so).\nSecond, I think innovation is the main role corporations have in producing social benefits because old ideas generally get replicated and produced more cheaply via capitalist competition. Just from looking at the major companies throughout my lifetime, they aren’t doing that much in the innovation department and just come and go. I feel like it would be a lot more effective to tie up the capital driving the direction of multiple very innovative and disruptive startups.\n","wordCount":"1342","inLanguage":"en","datePublished":"2022-12-03T09:48:39-05:00","dateModified":"2022-12-03T09:48:39-05:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jasonyang5.github.io/public/post/longtermism/"},"publisher":{"@type":"Organization","name":"Jason's Blog","logo":{"@type":"ImageObject","url":"https://jasonyang5.github.io/public/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://jasonyang5.github.io/public/ accesskey=h title="Home (Alt + H)">Home</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://jasonyang5.github.io/public/about title=About><span>About</span></a></li><li><a href=https://jasonyang5.github.io/public/tags title=Tags><span>Tags</span></a></li><li><a href=https://jasonyang5.github.io/public/categories title=Categories><span>Categories</span></a></li><li><a href=https://jasonyang5.github.io/public/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jasonyang5.github.io/public/>Home</a>&nbsp;»&nbsp;<a href=https://jasonyang5.github.io/public/post/>Posts</a></div><h1 class=post-title>In Defense of Effective Altruism after SBF</h1><div class=post-meta>December 3, 2022&nbsp;·&nbsp;Me</div></header><div class=post-content><p>Next threads to do</p><ul><li>Talk about social signalling</li><li>Once over the whole thing</li><li>Push out</li></ul><h1 id=intro-to-new-blog-category>Intro to new Blog Category<a hidden class=anchor aria-hidden=true href=#intro-to-new-blog-category>#</a></h1><p>I&rsquo;m adding a new category called &ldquo;Takes&rdquo;. For context, I enjoy taking time to think about my decisions, my process for making decisions, and how that relates to new info out in the world. Sometimes, this produces a hot take. These posts force me to organize that thinking and hopefully will provide entertainment for others. I try make reasonable claims most of the time, but mostly this is an exercise in logical thinking based on my experiences rather than researching to find out what&rsquo;s true.</p><h1 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h1><p>I don’t believe true effective altruists can hold billions of dollars for themselves (even if it’s not cash and in some less liquid asset ie stock needed to keep ownership).</p><p>Effective altruism is fairly broad with many interpretations. I think effective altruists seek to sustainably maximize well being for those they believe have moral relevance. I add sustainable because most people (myself included) wouldn&rsquo;t be interested in being effective altruists if doing so came at the expense of their whole life.</p><p>In this post, I consider two potential justifications for holding a billion dollars in assets. 1) that it&rsquo;s part of a broader earning to give strategy and 2) that it&rsquo;s needed to maintain decision rights of an impactful company.</p><h1 id=earning-to-give>Earning to Give<a hidden class=anchor aria-hidden=true href=#earning-to-give>#</a></h1><p>In this case, the altruists that are earning to give make a choice between the following (pretty long) list</p><ul><li>Cause A</li><li>Cause B</li><li>Cause C</li><li>&mldr;</li><li>Keeping the money for yourself</li></ul><p>Let&rsquo;s break this down into 2 sub choices: choosing between keeping the money and donating and with that donation pool choosing between the many causes to donate to.</p><p><strong>Keeping vs Donating</strong></p><p>I see the choice between donating and keeping driven by 2 main points</p><ol><li>Improving sustainability of future giving (buying food, basic hobbies, basic socialization, or capital investment)</li><li>Preference (are you actually altruistic?)</li></ol><p>Intuitively, effective altruists are more defined by their preference between donating and keeping money after adjusting for the fact that there is some reasonable amount they have to spend on themselves so they don&rsquo;t go insane.</p><p>This feels obvious to me, but I&rsquo;ll say that holding on to a billion dollars cannot possibly be justified by food, hobbies, and socialization. Even having multiple comically expensive hobbies like the same person buying a new ferrari every 2 months, 20 haute coture dresses at Paris fashion week, and a golf membership at Augusta National Golf Club each year only liberally sums to $3m per year (meaning you could set aside 15% of that $1b for yourself and donate the rest while sustaining &ldquo;basic hobbies and socialization needs&rdquo;). A billion dollars is a lot.</p><p>Capital investment could warrant keeping money for yourself. Suppose you&rsquo;re a entrepreneurial visionary and put out a good number of bangers every year and earn well over 20% per year on that capital. Then, why not just keep doing that and then donate a lump sum?</p><p>First, that type of donation profile isn&rsquo;t particularly sustainable and puts the job of efficient financing and investing through time on the nonprofits. This is problematic because the typical nonprofit has a bad investment opportunity set for transferring wealth into the future (no space in the top VC, hedge fund, private equity allocations) and an even worse one for taking wealth from the future (no capitalization, greater risk of default so likely have expensive financing).</p><p>Second, it&rsquo;s fairly undemocratic. This mode of donation makes the EA agenda concentrated in the hands of a few &ldquo;key moments&rdquo; and &ldquo;key players&rdquo; when I think should be more of a ongoing negotiation. It seems fair to say that those with billions of dollars have different preferences (ethical or otherwise) than those without which skews the &lsquo;moral&rsquo; agenda so to speak. For example, many (Elon Musk, SBF, Bezos, Bill Gates to an extent) are focused on longtermism and space exploration. It&rsquo;s a fine and obviously valuable cause, but I&rsquo;m skeptical that it&rsquo;s the correct allocation. See the below point on Cause A vs Cause B to see why I think we should have a more evenly weighted allocation.</p><p>Third, does this really happen in practice?</p><p><strong>Cause A vs Cause B</strong></p><p>Sub choice 2 is between causes. I think causes are impossible to reason between because any unified framework that compares causes will have extremely wide error bands that make the comparison inconclusive at best or entirely subjective at worst.</p><p>Take a classic example - global development aid versus minimizing existential risk. Let&rsquo;s use the expected quality adjusted life years framework for both. This requires 3 ingredients: the number of people benefitted, the quality of life improvement for those benefitted, and the probability that the intervention works.</p><p>Global development aid</p><ol><li>Number of people benefitted - known. Just take the population of countries in question.</li><li>Quality of life improvement - very difficult to compute, many conceptions of quality and several unexpected interaction terms (e.g. will development aid result in the government underinvest in its own infrastructure?)</li><li>Probability - more or less known if you choose a vetted charity with real research/randomized controlled trials backing the interventions.</li></ol><p>Existential risk</p><ol><li>Number of people benefitted - mostly known. Under reasonable assumptions, you could extrapolate the number of people that survive based on how long humanity survives. This number is very very high.</li><li>Quality of life improvement - basically throwing darts. Quality of life might be better than today given what we know about the past, but it could seriously turn for the worse in the long run. Who&rsquo;s to say some dictator doesn&rsquo;t take over the world in 500 years and kill everybody&rsquo;s quality of life for the next 500? It&rsquo;s really hard to reason out all the possibilities when you are thinking about the world 1,000 years in the future.</li><li>Probability - hard to argue a particular intervention actually moves the needle. This is a rant for another time, but just because the intervention could possibly/concievably work does not mean it has a positive probability of working. You can have possible outcomes that have 0 probability (e.g. picking a random real number from a hat of numbers uniformly distributed between 0 and 1). If the intervention possibly works but probability is still 0, the expected benefit of the intervention is still 0.</li></ol><p>You could do this comparison for several causes and end up in a spot with false precision - you&rsquo;re multiplying/adding together numbers with extremely wide error bands. It&rsquo;s not really any less subjective than choosing on vibes.</p><h1 id=managing-on-an-impactful-company>Managing on an Impactful Company<a hidden class=anchor aria-hidden=true href=#managing-on-an-impactful-company>#</a></h1><p>Some companies have materially changed the world (e.g. Azure/AWS efficient cloud computing, Tesla forcing the industry into EV&rsquo;s), and maintaining material management rights over the firm requires potentially billions of dollars in stock. The key here then is the marginal benefit of a manager/planner requiring stock to make those decisions rather than an individual contributor producing the innovations where holding stock isn&rsquo;t actually needed.</p><p>I have two main objections to keeping stock to drive the direction of the company.</p><p>First, it&rsquo;s important to remember the objective is to generally improve well being for the world rather than just the shareholders. So, it doesn&rsquo;t really matter who is providing the important services but rather that someone just does it. So, it&rsquo;s hard to justify the marginal dollars kept/spent on taking decision rights from someone else that is probably perfectly capable of running the company. On the innovation side, it&rsquo;s not clear why managers are the key driver over individual contributors coming up with ideas (that don&rsquo;t need stock to do so).</p><p>Second, I think innovation is the main role corporations have in producing social benefits because old ideas generally get replicated and produced more cheaply via capitalist competition. Just from looking at the major companies throughout my lifetime, they aren&rsquo;t doing that much in the innovation department and just come and go. I feel like it would be a lot more effective to tie up the capital driving the direction of multiple very innovative and disruptive startups.</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://jasonyang5.github.io/public/>Jason's Blog</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/public/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})});var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>